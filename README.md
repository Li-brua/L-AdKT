# Adversarial Knowledge Transfer for Black-Box Model Inversion Attack

This repository contains the code associated with the paper titled **"Adversarial Knowledge Transfer for Black-Box Model Inversion Attack"**, which has been accepted for publication at **ICASSP 2025**.

## Paper Overview

In this work, we propose a novel approach for **black-box model inversion attacks (MIA)** using **Adversarial Knowledge Transfer (AdKT)**. Our method significantly improves attack effectiveness by leveraging adversarial training techniques. The **L-AdKT** variant incorporates **label-controlled loss**, which helps further improve the quality of the generated images, preserving facial features and making the method state-of-the-art for model inversion attacks.

## Code Availability

The code for this paper will be made available soon. Please stay tuned!

**Coming Soon...**
